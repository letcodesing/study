#r2 0.62 이상
import pandas as pd

path = './_data/kaggle_house/'
wholl_train = pd.read_csv(path + 'train.csv')
wholl_test = pd.read_csv(path + 'test.csv')

print(wholl_train.info())
#non-null값 데이터유형 
print(wholl_train.describe())
#평균 등 수치
print(wholl_train.isnull().sum())



x = wholl_train.drop(['Street', 'Id', 'LotShape'], axis=1)
y = wholl_train['Alley']
print(x.shape)
print(y.shape)

print(x)
print(y)
#y는 어차피 결과값으로 나오는 것이기 때문에 여기서 전처리는 필요없다

print(x.shape)
print(y.shape)

print(x.columns)







from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state=66)







#2.모델

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

model=Sequential()
model.add(Dense(4, input_dim=78))
model.add(Dense(100))
model.add(Dense(1))

#3. 컴파일 훈련
model.compile(loss = 'mse', optimizer='adam')
model.fit(x_train, y_train, epochs=200, batch_size=100, validation_split=0.1)

#4. 평가, 예측
loss = model.evaluate(x_test, y_test)
print('loss', loss)

y_predict = model.predict(wholl_test)

from sklearn.metrics import r2_score
r2=r2_score(y_test, y_predict)
print('r2', r2)


#vali 적용전
# loss 3717.52490234375
# 3/3 [==============================] - 0s 836us/step
# r2 0.4271954209391574

# loss 3948.56884765625
# 3/3 [==============================] - 0s 999us/step
# r2 0.39159565035296795

# loss 3750.03271484375
# 3/3 [==============================] - 0s 500us/step
# r2 0.42218665427150825

#적용후
# loss 4267.72607421875
# 3/3 [==============================] - 0s 499us/step
# r2 0.3424191315644556

# loss 4283.685546875
# 3/3 [==============================] - 0s 997us/step
# r2 0.3399601997549837

# loss 4028.433349609375
# 3/3 [==============================] - 0s 998us/step
# r2 0.3792900271359142







def relu(p):
    return np.maximum(0, q)

y_summit = relu(y_predict)


